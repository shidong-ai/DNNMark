[DNNMark]
run_mode=composed

[Convolution]
name=block1_1_conv
n=64
c=3
h=224
w=224
previous_layer=null
conv_mode=convolution
kernel_size=3
num_output=64
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block1_1_conv
name=block1_1_relu
activation_mode=relu

[Convolution]
previous_layer=block1_1_relu
name=block1_2_conv
conv_mode=convolution
kernel_size=3
num_output=64
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block1_2_conv
name=block1_2_relu
activation_mode=relu

[Pooling]
previous_layer=block1_2_relu
name=pool1_2
pool_mode=max
kernel_size=2
pad=0
stride=2


[Convolution]
previous_layer=pool1_2
name=block2_1_conv
conv_mode=convolution
kernel_size=3
num_output=128
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_1_conv
name=block2_1_relu
activation_mode=relu

[Convolution]
previous_layer=block2_1_relu
name=block2_2_conv
conv_mode=convolution
kernel_size=3
num_output=128
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block2_2_conv
name=block2_2_relu
activation_mode=relu

[Pooling]
previous_layer=block2_2_relu
name=pool2_2
pool_mode=max
kernel_size=2
pad=0
stride=2

[Convolution]
previous_layer=pool2_2
name=block3_1_conv
conv_mode=convolution
kernel_size=3
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_1_conv
name=block3_1_relu
activation_mode=relu

[Convolution]
previous_layer=block3_1_relu
name=block3_2_conv
conv_mode=convolution
kernel_size=3
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_2_conv
name=block3_2_relu
activation_mode=relu

[Convolution]
previous_layer=block3_2_relu
name=block3_3_conv
conv_mode=convolution
kernel_size=3
num_output=256
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block3_3_conv
name=block3_3_relu
activation_mode=relu

[Pooling]
previous_layer=block3_3_relu
name=pool3_3
pool_mode=max
kernel_size=2
pad=0
stride=2

[Convolution]
previous_layer=pool3_3
name=block4_1_conv
conv_mode=convolution
kernel_size=3
num_output=512
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block4_1_conv
name=block4_1_relu
activation_mode=relu

[Convolution]
previous_layer=block4_1_relu
name=block4_2_conv
conv_mode=convolution
kernel_size=3
num_output=512
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block4_2_conv
name=block4_2_relu
activation_mode=relu

[Convolution]
previous_layer=block4_2_relu
name=block4_3_conv
conv_mode=convolution
kernel_size=3
num_output=512
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block4_3_conv
name=block4_3_relu
activation_mode=relu

[Pooling]
previous_layer=block4_3_relu
name=pool4_3
pool_mode=max
kernel_size=2
pad=0
stride=2

[Convolution]
previous_layer=pool4_3
name=block5_1_conv
conv_mode=convolution
kernel_size=3
num_output=512
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block5_1_conv
name=block5_1_relu
activation_mode=relu

[Convolution]
previous_layer=block5_1_relu
name=block5_2_conv
conv_mode=convolution
kernel_size=3
num_output=512
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block5_2_conv
name=block5_2_relu
activation_mode=relu

[Convolution]
previous_layer=block5_2_relu
name=block5_3_conv
conv_mode=convolution
kernel_size=3
num_output=512
pad=1
stride=1
conv_fwd_pref=fastest
conv_bwd_filter_pref=fastest
conv_bwd_data_pref=fastest

[Activation]
previous_layer=block5_3_conv
name=block5_3_relu
activation_mode=relu

[Pooling]
previous_layer=block5_3_relu
name=pool5_3
pool_mode=max
kernel_size=2
pad=0
stride=2

[FullyConnected]
previous_layer=pool5_3
name=fc1
num_output=4096

[Activation]
previous_layer=fc1
name=relu_fc1
activation_mode=relu

[FullyConnected]
previous_layer=relu_fc1
name=fc2
num_output=4096

[Activation]
previous_layer=fc2
name=relu_fc2
activation_mode=relu

[FullyConnected]
previous_layer=relu_fc2
name=fc3
num_output=1000

[Softmax]
name=softmax
previous_layer=fc3
softmax_algo=accurate
softmax_mode=channel


